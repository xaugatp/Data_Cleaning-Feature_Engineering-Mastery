# ğŸš€ 12-Week Data Cleaning & Feature Engineering Mastery Guide

> **From raw data â†’ clean dataset â†’ powerful features â†’ reproducible pipelines.**  
> A hands-on, portfolio-ready roadmap based on *Python for Data Analysis (3e)*, extended to 12 weeks with testing, leakage checks, geospatial/time series options, and automation/MLOps.

---

## ğŸ“… Program Overview

| Week | Theme | Status |
|------|-------|--------|
| 1 | ğŸ§¹ Data Familiarity & Baseline Cleaning | [ ] |
| 2 | â“ Missing Values Mastery | [ ] |
| 3 | ğŸš¦ Outliers, Anomalies & Transformations | [ ] |
| 4 | ğŸ·ï¸ Categorical Encoding & Cardinality Control | [ ] |
| 5 | â• Numerical Feature Creation | [ ] |
| 6 | â³ Dates, Time Features & Text Basics | [ ] |
| 7 | ğŸ“ Scaling, Normalization & Pipelines | [ ] |
| 8 | ğŸ”— Data Integration, Joins & Reshaping | [ ] |
| 9 | ğŸ¯ Feature Selection & Dimensionality Reduction | [ ] |
| 10 | ğŸ§ª Data Quality Testing & Automation | [ ] |
| 11 | ğŸ› ï¸ Domain Tracks (TS/NLP/Geo) | [ ] |
| 12 | ğŸ† Capstone: End-to-End Pipeline | [ ] |


---

## ğŸ—‚ï¸ How to Use This Guide
1. **Click the week title** to expand details.  
2. Follow **Objectives** â†’ **Deliverables** â†’ **Mini-project** â†’ **Short course**.  
3. Track progress in the table above.  
4. **Celebrate** after every week â€” data cleaning is a *superpower*. ğŸ¦¸â€â™€ï¸

---

<details>
<summary>ğŸ“… <strong>Week 1 â€“ Data Familiarity & Baseline Cleaning</strong></summary>

### ğŸ¯ Objectives
- Audit schema, dtypes, and value ranges
- Unify naming conventions
- Remove duplicates
- Build a data dictionary

### ğŸ“¦ Deliverables
- `data_dictionary.md`
- Column naming map
- Type-fix script
- Initial EDA/profile report

### ğŸ›  Mini-project
> Audit the Titanic dataset for naming consistency, duplicates, and dtype fixes.

### ğŸ“ Short course
[Kaggle â€“ Pandas](https://www.kaggle.com/learn/pandas)

ğŸ“– **PfDA 3e**: Ch5 Â§5.1â€“5.2, Ch6 Â§6.1, Ch7 Â§7.2, Ch3.3
</details>

---

<details>
<summary>ğŸ“… <strong>Week 2 â€“ Missing Values Mastery</strong></summary>

### ğŸ¯ Objectives
- Quantify missingness
- Visualize patterns of NA
- Choose imputation strategy per feature (drop, constant, KNN, MICE)

### ğŸ“¦ Deliverables
- Missingness report
- Imputation plan
- Before/after data quality table

### ğŸ›  Mini-project
> Use Missingno on the Housing dataset; test 3 imputation methods and compare downstream model impact.

### ğŸ“ Short course
[DataCamp â€“ Handling Missing Data](https://www.datacamp.com/courses/handling-missing-data-in-python)

ğŸ“– **PfDA 3e**: Ch7 Â§7.1, Ch6 Â§6.1
</details>

---

<details>
<summary>ğŸ“… <strong>Week 3 â€“ Outliers, Anomalies & Transformations</strong></summary>

### ğŸ¯ Objectives
- Detect outliers (IQR, Z-score, robust methods)
- Decide treat vs keep using domain context
- Apply transformations (e.g., Yeo-Johnson/Box-Cox)

### ğŸ“¦ Deliverables
- Outlier policy
- Transformation notebook
- Before/after distribution plots

### ğŸ›  Mini-project
> Apply IQR capping on Boston Housing; compare RMSE before vs after.

### ğŸ“ Short course
[Kaggle â€“ Data Cleaning](https://www.kaggle.com/learn/data-cleaning)

ğŸ“– **PfDA 3e**: Ch7 Â§7.2, Ch4 Â§4.3â€“4.4, Appendix A
</details>

---

<details>
<summary>ğŸ“… <strong>Week 4 â€“ Categorical Encoding & Cardinality Control</strong></summary>

### ğŸ¯ Objectives
- Clean categories (trim, unify, typo map)
- Group rare labels
- Apply safe encodings (OHE, ordinal, target/CatBoost, hashing) with CV

### ğŸ“¦ Deliverables
- Encoding matrix per feature
- Leakage-safe encoding wrapper

### ğŸ›  Mini-project
> Encode categorical vars in Titanic; benchmark One-Hot vs Target encoding.

### ğŸ“ Short course
[Kaggle â€“ Feature Engineering](https://www.kaggle.com/learn/feature-engineering)

ğŸ“– **PfDA 3e**: Ch7 Â§7.5, Ch7 Â§7.4, Ch12 Â§12.1â€“12.2
</details>

---

<details>
<summary>ğŸ“… <strong>Week 5 â€“ Numerical Feature Creation</strong></summary>

### ğŸ¯ Objectives
- Create groupby aggregations
- Engineer ratios/interactions
- Apply binning and transformations

### ğŸ“¦ Deliverables
- Feature spec (name, formula, null policy, range)
- Top-k features by MI/Gini

### ğŸ›  Mini-project
> Create ride-duration and avg-speed features for NYC Taxi data; evaluate via CV.

### ğŸ“ Short course
[Kaggle â€“ Feature Engineering](https://www.kaggle.com/learn/feature-engineering)

ğŸ“– **PfDA 3e**: Ch10 Â§10.1â€“10.4, Ch5 Â§5.3, Ch4 Â§4.3
</details>

---

<details>
<summary>ğŸ“… <strong>Week 6 â€“ Dates, Time Features & Text Basics</strong></summary>

### ğŸ¯ Objectives
- Extract date parts and cyclical encodings
- Add holiday flags and lags
- Text cleaning, counts, simple sentiment

### ğŸ“¦ Deliverables
- Time-aware feature cookbook
- Text preprocessing pipeline

### ğŸ›  Mini-project
> Create lag features on retail sales; compute TF-IDF & sentiment on Tweets.

### ğŸ“ Short course
[Kaggle â€“ Time Series](https://www.kaggle.com/learn/time-series) & NLP basics

ğŸ“– **PfDA 3e**: Ch11 Â§11.1â€“11.7, Ch6 Â§6.1, Ch7 Â§7.4
</details>

---

<details>
<summary>ğŸ“… <strong>Week 7 â€“ Scaling, Normalization & Pipelines</strong></summary>

### ğŸ¯ Objectives
- Apply scaling methods (Standard, Min-Max, Robust)
- Build scikit-learn Pipelines & ColumnTransformers
- Persist preprocessing with joblib

### ğŸ“¦ Deliverables
- End-to-end preprocessing pipeline (fit/transform)
- Save/load demonstration

### ğŸ›  Mini-project
> Compare models with Min-Max vs StandardScaler on credit data within a Pipeline.

### ğŸ“ Short course
[scikit-learn â€“ Preprocessing (User Guide)](https://scikit-learn.org/stable/modules/preprocessing.html)

ğŸ“– **PfDA 3e**: Ch12 Â§12.4, Ch12 Â§12.1
</details>

---

<details>
<summary>ğŸ“… <strong>Week 8 â€“ Data Integration, Joins & Reshaping</strong></summary>

### ğŸ¯ Objectives
- Perform safe merges with key audits
- Use anti-joins to find orphans
- Reshape with pivot/melt; use concat/append appropriately

### ğŸ“¦ Deliverables
- Join QA checklist
- Keys coverage report (match rate, dupes, one-to-many audits)

### ğŸ›  Mini-project
> Merge ads spend with sales by date/region; quantify orphan rows and row inflation.

### ğŸ“ Short course
[Pandas merge/reshape documentation](https://pandas.pydata.org/docs/user_guide/merging.html)

ğŸ“– **PfDA 3e**: Ch8 Â§8.1â€“8.3, Ch6 Â§6.3â€“6.4
</details>

---

<details>
<summary>ğŸ“… <strong>Week 9 â€“ Feature Selection & Dimensionality Reduction</strong></summary>

### ğŸ¯ Objectives
- Apply filter (corr/MI), wrapper (RFE), and embedded (L1/trees) methods
- Explore PCA/UMAP for visualization
- Validate feature subsets without leakage

### ğŸ“¦ Deliverables
- Feature selection report
- Compact, validated feature set

### ğŸ›  Mini-project
> Run RFE and L1 on churn data; compare baseline vs selected features.

### ğŸ“ Short course
[StatQuest â€“ Feature Selection](https://www.youtube.com/watch?v=Q6f7m5Yb0P8)

ğŸ“– **PfDA 3e**: Ch12 Â§12.4, Ch10 (foundations)
</details>

---

<details>
<summary>ğŸ“… <strong>Week 10 â€“ Data Quality Testing & Automation</strong></summary>

### ğŸ¯ Objectives
- Create schema/range/null/uniqueness tests
- Add Pytest + (Pandera or Great Expectations)
- Wire basic CI to block failing data jobs

### ğŸ“¦ Deliverables
- Pandera or GE suite
- pytest unit tests
- Pre-commit hooks and CI badge

### ğŸ›  Mini-project
> Create a Great Expectations suite for Titanic and fail the pipeline on violations.

### ğŸ“ Short course
[Great Expectations â€“ Quickstart](https://greatexpectations.io/)

ğŸ“– **PfDA 3e**: Ch6 (I/O pitfalls), Ch3.3 (Files & OS)
</details>

---

<details>
<summary>ğŸ“… <strong>Week 11 â€“ Domain Tracks (Choose 1â€“2)</strong></summary>

### â³ Time Series
- **Objectives:** Time-based splits, leakage prevention, lag/rolling features, calendar effects  
- **Mini-project:** M5-like retail demand subset with lags/rolls; evaluate on time-based CV  
- **Short course:** [Kaggle â€“ Time Series](https://www.kaggle.com/learn/time-series)  
- **PfDA 3e:** Ch11 (full chapter)

### ğŸ“ NLP
- **Objectives:** Text normalization vs retention, vocabulary drift, feature hashing for scale  
- **Mini-project:** IMDB reviews TF-IDF + sentiment classification; analyze leakage risks  
- **Short course:** [Kaggle â€“ NLP](https://www.kaggle.com/learn/nlp)  
- **PfDA 3e:** Ch7 Â§7.4â€“7.5

### ğŸ—º Geospatial
- **Objectives:** Handle raster stacks & CRS alignment, compute NDVI/texture, aggregate patches  
- **Mini-project:** Compute NDVI from Sentinel-2 for a small AOI; build basic features  
- **Short course:** [Kaggle â€“ Geospatial Analysis](https://www.kaggle.com/learn/geospatial-analysis)  
- **PfDA 3e:** External resources (not covered)
</details>

---

<details>
<summary>ğŸ“… <strong>Week 12 â€“ Capstone: End-to-End, Reproducible & Documented</strong></summary>

### ğŸ¯ Objectives
- Package your pipeline with custom transformers
- Document reproducible steps and lock environments
- Present metrics comparing baseline vs engineered features

### ğŸ“¦ Deliverables
- Packaged `src/` with CLI entry point
- README with repro steps
- Environment lockfile
- Model metrics report

### ğŸ›  Mini-project
> Single-command pipeline from raw â†’ clean â†’ features â†’ model evaluation producing a `reports/` bundle.

### ğŸ“ Short course
Review prior resources; skim sklearn docs for any gaps

ğŸ“– **PfDA 3e**: Ch13, skim Ch5, Ch7, Ch8, Ch10
</details>

---

## ğŸ§  Key Notes & Pro Tips
ğŸ’¡ **Avoid leakage:**  
- Always fit transformers only on training folds.  
- For target encoding, wrap inside CV folds or use encoders with built-in CV.

ğŸ” **Data QA:**  
- Run schema, bounds, null %, and uniqueness tests before merges and at outputs.

ğŸ— **Join hygiene:**  
- Track match rates and orphan rows with anti-joins.

ğŸ“¦ **Persistence:**  
- Save artifacts with `joblib`, version datasets with DVC.

---

## ğŸ“œ License
MIT License â€” free to learn, share, and adapt.

Copyright (c) 2025 Saugat Poudel

---

## ğŸ“£ Share Your Progress
If you complete a week, share your mini-project on GitHub with the tag:  
